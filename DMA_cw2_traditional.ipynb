{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from hmmlearn import hmm\n",
    "from sklearn.metrics import classification_report\n",
    "# from sklearn.externals import joblib\n",
    "# from sklearn.utils import joblib\n",
    "import joblib\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install hmmlearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data\n",
    "# 加载数据\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "def load_data(data_dir):\n",
    "    gestures = [\"circle\", \"wave\", \"comeHere\", \"goAway\"]\n",
    "    data = []\n",
    "    labels = []\n",
    "\n",
    "    for gesture in gestures:\n",
    "        for i in range(1, 6):\n",
    "            file_path = os.path.join(data_dir, f\"{gesture}_{i}.csv\")\n",
    "            df = pd.read_csv(file_path)\n",
    "            gesture_data = df[[\"Linear Acceleration x (m/s^2)\", \"Linear Acceleration y (m/s^2)\", \"Linear Acceleration z (m/s^2)\"]].values\n",
    "            data.append(gesture_data)\n",
    "            labels.append(gesture)\n",
    "\n",
    "    return data, labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature extraction\n",
    "def feature_extraction(data, labels):\n",
    "    features = []\n",
    "    feature_labels = []\n",
    "\n",
    "    window_size = 240\n",
    "    step_size = 10\n",
    "\n",
    "    for gesture_data, label in zip(data, labels):\n",
    "        for i in range(0, len(gesture_data) - window_size, step_size):\n",
    "            window = gesture_data[i:i + window_size]\n",
    "            feature = calculate_features(window)\n",
    "            features.append(feature)\n",
    "            feature_labels.append(label)\n",
    "\n",
    "    return features, feature_labels\n",
    "\n",
    "def calculate_features(window):\n",
    "    mean_x = np.mean(window[:, 0])\n",
    "    mean_y = np.mean(window[:, 1])\n",
    "    mean_z = np.mean(window[:, 2])\n",
    "\n",
    "    max_x = np.max(window[:, 0])\n",
    "    max_y = np.max(window[:, 1])\n",
    "    max_z = np.max(window[:, 2])\n",
    "\n",
    "    min_x = np.min(window[:, 0])\n",
    "    min_y = np.min(window[:, 1])\n",
    "    min_z = np.min(window[:, 2])\n",
    "\n",
    "    return [mean_x, mean_y, mean_z, max_x, max_y, max_z, min_x, min_y, min_z]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data preprocess\n",
    "def preprocess_data(features, scaler=None):\n",
    "    if scaler is None:\n",
    "        scaler = StandardScaler()\n",
    "        processed_data = scaler.fit_transform(features)\n",
    "    else:\n",
    "        processed_data = scaler.transform(features)\n",
    "    return processed_data, scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dataset partitioning\n",
    "def split_data(features, labels, test_size=0.2, random_state=42):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=test_size, random_state=random_state)\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model train\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "def train_svm(X_train, y_train):\n",
    "    svm = SVC()\n",
    "    svm.fit(X_train, y_train)\n",
    "    return svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "def train_decision_tree(X_train, y_train):\n",
    "    decision_tree = DecisionTreeClassifier()\n",
    "    decision_tree.fit(X_train, y_train)\n",
    "    return decision_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "def train_random_forest(X_train, y_train):\n",
    "    random_forest = RandomForestClassifier()\n",
    "    random_forest.fit(X_train, y_train)\n",
    "    return random_forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import classification_report\n",
    "def evaluate_model(model, X_test, y_test, target_names):\n",
    "    y_pred = model.predict(X_test)\n",
    "    report = classification_report(y_test, y_pred, target_names=target_names)\n",
    "    print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "def save_model(model, model_name):\n",
    "    joblib.dump(model, f\"{model_name}.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#testing section\n",
    "def load_csv(file_path):\n",
    "    data = []\n",
    "    df = pd.read_csv(file_path)\n",
    "    gesture_data = df[[\"Linear Acceleration x (m/s^2)\", \"Linear Acceleration y (m/s^2)\", \"Linear Acceleration z (m/s^2)\"]].values\n",
    "    data.append(gesture_data)\n",
    "#     return gesture_data\n",
    "    return data\n",
    "\n",
    "def sliding_window(data, window_size, step_size):\n",
    "    windows = []\n",
    "    for i in range(0, len(data) - window_size, step_size):\n",
    "        window = data[i:i + window_size]\n",
    "        windows.append(window)\n",
    "\n",
    "    return windows\n",
    "\n",
    "def feature_extraction_test(data):\n",
    "    features = []\n",
    "\n",
    "    window_size = 240\n",
    "    step_size = 10\n",
    "\n",
    "    for gesture_data in data:\n",
    "        for i in range(0, len(gesture_data) - window_size, step_size):\n",
    "            window = gesture_data[i:i + window_size]\n",
    "            feature = calculate_features(window)\n",
    "            features.append(feature)\n",
    "#     print(\"Extracted features:\", features)\n",
    "\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#testing whole files\n",
    "def test_model_on_whole_files(model, test_data_dir, scaler):\n",
    "    gestures = [\"circle\", \"wave\", \"comeHere\", \"goAway\"]\n",
    "    correct_count = 0\n",
    "    total_count = 0\n",
    "\n",
    "    for gesture in gestures:\n",
    "        for i in range(1, 6):\n",
    "            file_path = os.path.join(test_data_dir, f\"{gesture}_test_{i}.csv\")\n",
    "            gesture_data = load_csv(file_path)\n",
    "            features = feature_extraction_test(gesture_data)\n",
    "            \n",
    "            if not features:\n",
    "                print(f\"Features for {gesture}_test_{i} are empty. Skipping this file.\")\n",
    "                continue\n",
    "            \n",
    "#             processed_features = scaler.transform([features])\n",
    "            processed_features, _ = preprocess_data(features, scaler)\n",
    "            prediction = model.predict(processed_features)\n",
    "            \n",
    "            print(f\"Actual: {gesture} | Predicted: {prediction[0]}\")\n",
    "            \n",
    "            if prediction[0] == gesture:\n",
    "                correct_count += 1\n",
    "            total_count += 1\n",
    "\n",
    "    accuracy = correct_count / total_count\n",
    "    print(f\"Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split data and test part of file\n",
    "def split_data_into_parts(data, num_parts):\n",
    "    data_array = data[0]\n",
    "    data_length = len(data_array)\n",
    "    part_size = data_length // num_parts\n",
    "    \n",
    "    data_parts = []\n",
    "    \n",
    "    for i in range(0, data_length, part_size):\n",
    "        start_index = i\n",
    "        end_index = i + part_size if i + part_size < data_length else data_length\n",
    "        part_data = data_array[start_index:end_index]\n",
    "        data_parts.append([part_data])  # 将 part_data 放入一个列表中，使数据结构与 load_csv() 相同\n",
    "    \n",
    "    return data_parts\n",
    "\n",
    "\n",
    "def test_model_on_file_parts(model, test_data_dir, scaler, num_parts=3):\n",
    "    gestures = [\"circle\", \"wave\", \"comeHere\", \"goAway\"]\n",
    "    correct_count = 0\n",
    "    total_count = 0\n",
    "\n",
    "    for gesture in gestures:\n",
    "        for i in range(1, 6):\n",
    "            file_path = os.path.join(test_data_dir, f\"{gesture}_test_{i}.csv\")\n",
    "            gesture_data = load_csv(file_path)\n",
    "#             print(\"the data is: \",gesture_data)\n",
    "            data_parts = split_data_into_parts(gesture_data, num_parts)\n",
    "#             print(\"data_parts is: \", data_parts)\n",
    "            \n",
    "            for j, part_data in enumerate(data_parts):\n",
    "#                 print(\"len(part_data) and part_data is \", len(part_data), part_data)\n",
    "                features = feature_extraction_test(part_data)\n",
    "                \n",
    "                if not features:\n",
    "                    print(f\"Features for {gesture}_test_{i}_part_{j + 1} are empty. Skipping this part.\")\n",
    "                    continue\n",
    "                \n",
    "                processed_features, _ = preprocess_data(features, scaler)\n",
    "                prediction = model.predict(processed_features)\n",
    "                \n",
    "                print(f\"Actual: {gesture} | Predicted: {prediction[0]} | File: {gesture}_test_{i}_part_{j + 1}\")\n",
    "                \n",
    "                if prediction[0] == gesture:\n",
    "                    correct_count += 1\n",
    "                total_count += 1\n",
    "\n",
    "    accuracy = correct_count / total_count\n",
    "    print(f\"Accuracy: {accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM evaluation:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      circle       1.00      1.00      1.00       147\n",
      "        wave       1.00      1.00      1.00       103\n",
      "    comeHere       1.00      1.00      1.00       118\n",
      "      goAway       1.00      1.00      1.00        83\n",
      "\n",
      "    accuracy                           1.00       451\n",
      "   macro avg       1.00      1.00      1.00       451\n",
      "weighted avg       1.00      1.00      1.00       451\n",
      "\n",
      "Decision Tree evaluation:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      circle       1.00      1.00      1.00       147\n",
      "        wave       1.00      1.00      1.00       103\n",
      "    comeHere       1.00      1.00      1.00       118\n",
      "      goAway       1.00      1.00      1.00        83\n",
      "\n",
      "    accuracy                           1.00       451\n",
      "   macro avg       1.00      1.00      1.00       451\n",
      "weighted avg       1.00      1.00      1.00       451\n",
      "\n",
      "Random Forest evaluation:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      circle       1.00      1.00      1.00       147\n",
      "        wave       1.00      1.00      1.00       103\n",
      "    comeHere       1.00      1.00      1.00       118\n",
      "      goAway       1.00      1.00      1.00        83\n",
      "\n",
      "    accuracy                           1.00       451\n",
      "   macro avg       1.00      1.00      1.00       451\n",
      "weighted avg       1.00      1.00      1.00       451\n",
      "\n",
      "Actual: circle | Predicted: circle\n",
      "Actual: circle | Predicted: circle\n",
      "Actual: circle | Predicted: wave\n",
      "Actual: circle | Predicted: wave\n",
      "Actual: circle | Predicted: wave\n",
      "Actual: wave | Predicted: wave\n",
      "Actual: wave | Predicted: wave\n",
      "Actual: wave | Predicted: wave\n",
      "Actual: wave | Predicted: wave\n",
      "Actual: wave | Predicted: wave\n",
      "Actual: comeHere | Predicted: goAway\n",
      "Actual: comeHere | Predicted: goAway\n",
      "Actual: comeHere | Predicted: comeHere\n",
      "Actual: comeHere | Predicted: goAway\n",
      "Actual: comeHere | Predicted: comeHere\n",
      "Actual: goAway | Predicted: goAway\n",
      "Actual: goAway | Predicted: comeHere\n",
      "Actual: goAway | Predicted: goAway\n",
      "Actual: goAway | Predicted: goAway\n",
      "Actual: goAway | Predicted: goAway\n",
      "Accuracy: 0.65\n",
      "Actual: circle | Predicted: circle | File: circle_test_1_part_1\n",
      "Actual: circle | Predicted: circle | File: circle_test_1_part_2\n",
      "Actual: circle | Predicted: wave | File: circle_test_1_part_3\n",
      "Actual: circle | Predicted: circle | File: circle_test_2_part_1\n",
      "Actual: circle | Predicted: wave | File: circle_test_2_part_2\n",
      "Actual: circle | Predicted: wave | File: circle_test_2_part_3\n",
      "Features for circle_test_2_part_4 are empty. Skipping this part.\n",
      "Actual: circle | Predicted: wave | File: circle_test_3_part_1\n",
      "Actual: circle | Predicted: wave | File: circle_test_3_part_2\n",
      "Actual: circle | Predicted: wave | File: circle_test_3_part_3\n",
      "Features for circle_test_3_part_4 are empty. Skipping this part.\n",
      "Actual: circle | Predicted: wave | File: circle_test_4_part_1\n",
      "Actual: circle | Predicted: wave | File: circle_test_4_part_2\n",
      "Actual: circle | Predicted: wave | File: circle_test_4_part_3\n",
      "Actual: circle | Predicted: wave | File: circle_test_5_part_1\n",
      "Actual: circle | Predicted: wave | File: circle_test_5_part_2\n",
      "Actual: circle | Predicted: wave | File: circle_test_5_part_3\n",
      "Features for circle_test_5_part_4 are empty. Skipping this part.\n",
      "Actual: wave | Predicted: wave | File: wave_test_1_part_1\n",
      "Actual: wave | Predicted: wave | File: wave_test_1_part_2\n",
      "Actual: wave | Predicted: wave | File: wave_test_1_part_3\n",
      "Features for wave_test_1_part_4 are empty. Skipping this part.\n",
      "Actual: wave | Predicted: wave | File: wave_test_2_part_1\n",
      "Actual: wave | Predicted: wave | File: wave_test_2_part_2\n",
      "Actual: wave | Predicted: wave | File: wave_test_2_part_3\n",
      "Features for wave_test_2_part_4 are empty. Skipping this part.\n",
      "Actual: wave | Predicted: wave | File: wave_test_3_part_1\n",
      "Actual: wave | Predicted: wave | File: wave_test_3_part_2\n",
      "Actual: wave | Predicted: wave | File: wave_test_3_part_3\n",
      "Features for wave_test_3_part_4 are empty. Skipping this part.\n",
      "Actual: wave | Predicted: wave | File: wave_test_4_part_1\n",
      "Actual: wave | Predicted: wave | File: wave_test_4_part_2\n",
      "Actual: wave | Predicted: wave | File: wave_test_4_part_3\n",
      "Actual: wave | Predicted: wave | File: wave_test_5_part_1\n",
      "Actual: wave | Predicted: wave | File: wave_test_5_part_2\n",
      "Actual: wave | Predicted: wave | File: wave_test_5_part_3\n",
      "Actual: comeHere | Predicted: goAway | File: comeHere_test_1_part_1\n",
      "Actual: comeHere | Predicted: comeHere | File: comeHere_test_1_part_2\n",
      "Actual: comeHere | Predicted: goAway | File: comeHere_test_1_part_3\n",
      "Features for comeHere_test_1_part_4 are empty. Skipping this part.\n",
      "Actual: comeHere | Predicted: goAway | File: comeHere_test_2_part_1\n",
      "Actual: comeHere | Predicted: goAway | File: comeHere_test_2_part_2\n",
      "Actual: comeHere | Predicted: goAway | File: comeHere_test_2_part_3\n",
      "Features for comeHere_test_2_part_4 are empty. Skipping this part.\n",
      "Actual: comeHere | Predicted: comeHere | File: comeHere_test_3_part_1\n",
      "Actual: comeHere | Predicted: comeHere | File: comeHere_test_3_part_2\n",
      "Actual: comeHere | Predicted: comeHere | File: comeHere_test_3_part_3\n",
      "Actual: comeHere | Predicted: goAway | File: comeHere_test_4_part_1\n",
      "Actual: comeHere | Predicted: comeHere | File: comeHere_test_4_part_2\n",
      "Actual: comeHere | Predicted: comeHere | File: comeHere_test_4_part_3\n",
      "Features for comeHere_test_4_part_4 are empty. Skipping this part.\n",
      "Actual: comeHere | Predicted: comeHere | File: comeHere_test_5_part_1\n",
      "Actual: comeHere | Predicted: comeHere | File: comeHere_test_5_part_2\n",
      "Actual: comeHere | Predicted: comeHere | File: comeHere_test_5_part_3\n",
      "Features for comeHere_test_5_part_4 are empty. Skipping this part.\n",
      "Actual: goAway | Predicted: goAway | File: goAway_test_1_part_1\n",
      "Actual: goAway | Predicted: goAway | File: goAway_test_1_part_2\n",
      "Actual: goAway | Predicted: comeHere | File: goAway_test_1_part_3\n",
      "Features for goAway_test_1_part_4 are empty. Skipping this part.\n",
      "Actual: goAway | Predicted: comeHere | File: goAway_test_2_part_1\n",
      "Actual: goAway | Predicted: goAway | File: goAway_test_2_part_2\n",
      "Actual: goAway | Predicted: circle | File: goAway_test_2_part_3\n",
      "Features for goAway_test_2_part_4 are empty. Skipping this part.\n",
      "Actual: goAway | Predicted: goAway | File: goAway_test_3_part_1\n",
      "Actual: goAway | Predicted: wave | File: goAway_test_3_part_2\n",
      "Actual: goAway | Predicted: goAway | File: goAway_test_3_part_3\n",
      "Features for goAway_test_3_part_4 are empty. Skipping this part.\n",
      "Actual: goAway | Predicted: goAway | File: goAway_test_4_part_1\n",
      "Actual: goAway | Predicted: goAway | File: goAway_test_4_part_2\n",
      "Actual: goAway | Predicted: goAway | File: goAway_test_4_part_3\n",
      "Features for goAway_test_4_part_4 are empty. Skipping this part.\n",
      "Actual: goAway | Predicted: goAway | File: goAway_test_5_part_1\n",
      "Actual: goAway | Predicted: comeHere | File: goAway_test_5_part_2\n",
      "Actual: goAway | Predicted: comeHere | File: goAway_test_5_part_3\n",
      "Accuracy: 0.6\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    data_dir = \"data\"\n",
    "    data, labels = load_data(data_dir)\n",
    "\n",
    "    target_names = [\"circle\", \"wave\", \"comeHere\", \"goAway\"]\n",
    "\n",
    "    features, feature_labels = feature_extraction(data, labels)\n",
    "    processed_data, train_scaler  = preprocess_data(features)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = split_data(processed_data, feature_labels)\n",
    "\n",
    "    # Train and evaluate SVM model\n",
    "    svm_model = train_svm(X_train, y_train)\n",
    "    print(\"SVM evaluation:\")\n",
    "    evaluate_model(svm_model, X_test, y_test, target_names)\n",
    "\n",
    "    # Train and evaluate Decision Tree model\n",
    "    decision_tree_model = train_decision_tree(X_train, y_train)\n",
    "    print(\"Decision Tree evaluation:\")\n",
    "    evaluate_model(decision_tree_model, X_test, y_test, target_names)\n",
    "\n",
    "    # Train and evaluate Random Forest model\n",
    "    random_forest_model = train_random_forest(X_train, y_train)\n",
    "    print(\"Random Forest evaluation:\")\n",
    "    evaluate_model(random_forest_model, X_test, y_test, target_names)\n",
    "    \n",
    "    #test\n",
    "    test_model_on_whole_files(svm_model, \"data_test\",train_scaler)\n",
    "    test_model_on_file_parts(svm_model, \"data_test\", train_scaler)\n",
    "    \n",
    "    # Save models\n",
    "    save_model(svm_model, \"svm_model\")\n",
    "    save_model(decision_tree_model, \"decision_tree_model\")\n",
    "    save_model(random_forest_model, \"random_forest_model\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
